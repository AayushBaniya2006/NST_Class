{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 â€” Model Training\n",
    "Train EfficientNetV2-S and ResNet50 on cleaned Fitzpatrick17k data.\n",
    "Two-phase training: frozen backbone then fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for Colab\n",
    "# !pip install -q wandb timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "from src.data.dataset import FitzpatrickDataset\n",
    "from src.data.transforms import get_train_transforms, get_eval_transforms\n",
    "from src.models.classifier import SkinToneClassifier\n",
    "from src.training.config import TrainingConfig\n",
    "from src.training.trainer import Trainer, compute_class_weights\n",
    "from src.utils.logging import init_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = TrainingConfig(\n",
    "    backbone=\"efficientnet_v2_s\",\n",
    "    num_classes=3,\n",
    "    pretrained=True,\n",
    "    freeze_backbone=True,\n",
    "    unfreeze_after_epochs=5,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    learning_rate=1e-4,\n",
    "    early_stopping_patience=5,\n",
    "    use_class_weights=True,\n",
    "    wandb_project=\"skin-tone-classifier\",\n",
    ")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "IMAGE_DIR = \"data/images\"\n",
    "DATA_DIR = \"data/cleaned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data splits\n",
    "train_df = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n",
    "val_df = pd.read_csv(f\"{DATA_DIR}/val.csv\")\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n",
    "print(f\"Train distribution:\\n{train_df['skin_tone_group'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and loaders\n",
    "train_transform = get_train_transforms(config.image_size)\n",
    "eval_transform = get_eval_transforms(config.image_size)\n",
    "\n",
    "train_dataset = FitzpatrickDataset(train_df, IMAGE_DIR, transform=train_transform)\n",
    "val_dataset = FitzpatrickDataset(val_df, IMAGE_DIR, transform=eval_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config.batch_size,\n",
    "    shuffle=True, num_workers=config.num_workers, pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=config.batch_size,\n",
    "    shuffle=False, num_workers=config.num_workers, pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "labels = train_df[\"skin_tone_label\"].tolist()\n",
    "weights = compute_class_weights(labels, num_classes=3)\n",
    "class_weights = torch.tensor(weights, dtype=torch.float32)\n",
    "print(f\"Class weights: {weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = SkinToneClassifier(\n",
    "    backbone_name=config.backbone,\n",
    "    num_classes=config.num_classes,\n",
    "    pretrained=config.pretrained,\n",
    ")\n",
    "if config.freeze_backbone:\n",
    "    model.freeze_backbone()\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total params: {total_params:,}\")\n",
    "print(f\"Trainable params: {trainable_params:,} ({trainable_params/total_params:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize W&B\n",
    "run = init_wandb(\n",
    "    project=config.wandb_project,\n",
    "    config=vars(config),\n",
    "    run_name=f\"{config.backbone}_lr{config.learning_rate}_bs{config.batch_size}\",\n",
    "    tags=[\"milestone1\", config.backbone],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    class_weights=class_weights if config.use_class_weights else None,\n",
    "    device=DEVICE,\n",
    "    wandb_run=run,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "epochs = range(1, len(history[\"train\"]) + 1)\n",
    "\n",
    "axes[0].plot(epochs, [m[\"loss\"] for m in history[\"train\"]], label=\"Train\")\n",
    "axes[0].plot(epochs, [m[\"loss\"] for m in history[\"val\"]], label=\"Val\")\n",
    "axes[0].set_title(\"Loss\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(epochs, [m[\"accuracy\"] for m in history[\"train\"]], label=\"Train\")\n",
    "axes[1].plot(epochs, [m[\"accuracy\"] for m in history[\"val\"]], label=\"Val\")\n",
    "axes[1].set_title(\"Accuracy\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(epochs, [m[\"f1\"] for m in history[\"train\"]], label=\"Train\")\n",
    "axes[2].plot(epochs, [m[\"f1\"] for m in history[\"val\"]], label=\"Val\")\n",
    "axes[2].set_title(\"Macro F1\")\n",
    "axes[2].set_xlabel(\"Epoch\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model artifact\n",
    "Path(\"checkpoints\").mkdir(exist_ok=True)\n",
    "torch.save(model.state_dict(), f\"checkpoints/{config.backbone}_final.pt\")\n",
    "wandb.save(f\"checkpoints/{config.backbone}_final.pt\")\n",
    "print(f\"Model saved to checkpoints/{config.backbone}_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish W&B run\n",
    "wandb.finish()\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ResNet50\n",
    "Change backbone to `resnet50` and re-run cells above, or copy and modify the config below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train ResNet50, create a new config and repeat the training:\n",
    "# config_resnet = TrainingConfig(backbone=\"resnet50\", ...)\n",
    "# Then re-run the model init, trainer, and training cells above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
