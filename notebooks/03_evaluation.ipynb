{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 â€” Evaluation & Fairness Analysis\n",
    "Evaluate EfficientNetV2-S, ResNet50, and AutoML baseline.\n",
    "Compute per-class metrics and fairness gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.data.dataset import FitzpatrickDataset\n",
    "from src.data.transforms import get_eval_transforms\n",
    "from src.models.classifier import SkinToneClassifier\n",
    "from src.evaluation.metrics import compute_all_metrics\n",
    "from src.evaluation.fairness import compute_fairness_gap, compare_model_fairness\n",
    "from src.evaluation.confusion import plot_confusion_matrix, plot_fairness_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMAGE_DIR = \"data/images\"\n",
    "DATA_DIR = \"data/cleaned\"\n",
    "CLASS_NAMES = [\"12\", \"34\", \"56\"]\n",
    "DISPLAY_NAMES = [\"Fitz I-II\", \"Fitz III-IV\", \"Fitz V-VI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(f\"{DATA_DIR}/test.csv\")\n",
    "print(f\"Test set: {len(test_df)} images\")\n",
    "print(test_df[\"skin_tone_group\"].value_counts().sort_index())\n",
    "\n",
    "transform = get_eval_transforms(224)\n",
    "test_dataset = FitzpatrickDataset(test_df, IMAGE_DIR, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: run inference\n",
    "@torch.no_grad()\n",
    "def get_predictions(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return np.array(all_labels), np.array(all_preds), np.array(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate EfficientNetV2-S\n",
    "model_eff = SkinToneClassifier(\"efficientnet_v2_s\", num_classes=3, pretrained=False)\n",
    "model_eff.load_state_dict(torch.load(\"checkpoints/efficientnet_v2_s_final.pt\", map_location=DEVICE))\n",
    "model_eff = model_eff.to(DEVICE)\n",
    "\n",
    "y_true, y_pred_eff, y_proba_eff = get_predictions(model_eff, test_loader, DEVICE)\n",
    "metrics_eff = compute_all_metrics(y_true, y_pred_eff, y_proba_eff, CLASS_NAMES)\n",
    "\n",
    "print(\"EfficientNetV2-S Results:\")\n",
    "print(f\"  Accuracy: {metrics_eff['accuracy']:.4f}\")\n",
    "print(f\"  Macro F1: {metrics_eff['macro_f1']:.4f}\")\n",
    "print(f\"  ROC-AUC:  {metrics_eff['roc_auc']:.4f}\")\n",
    "for cls in CLASS_NAMES:\n",
    "    m = metrics_eff[\"per_class\"][cls]\n",
    "    print(f\"  {cls}: P={m['precision']:.3f} R={m['recall']:.3f} F1={m['f1']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix: EfficientNetV2\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "plot_confusion_matrix(\n",
    "    metrics_eff[\"confusion_matrix\"],\n",
    "    DISPLAY_NAMES,\n",
    "    title=\"EfficientNetV2-S Confusion Matrix\",\n",
    "    save_path=\"results/cm_efficientnet.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ResNet50\n",
    "model_res = SkinToneClassifier(\"resnet50\", num_classes=3, pretrained=False)\n",
    "model_res.load_state_dict(torch.load(\"checkpoints/resnet50_final.pt\", map_location=DEVICE))\n",
    "model_res = model_res.to(DEVICE)\n",
    "\n",
    "_, y_pred_res, y_proba_res = get_predictions(model_res, test_loader, DEVICE)\n",
    "metrics_res = compute_all_metrics(y_true, y_pred_res, y_proba_res, CLASS_NAMES)\n",
    "\n",
    "print(\"\\nResNet50 Results:\")\n",
    "print(f\"  Accuracy: {metrics_res['accuracy']:.4f}\")\n",
    "print(f\"  Macro F1: {metrics_res['macro_f1']:.4f}\")\n",
    "for cls in CLASS_NAMES:\n",
    "    m = metrics_res[\"per_class\"][cls]\n",
    "    print(f\"  {cls}: P={m['precision']:.3f} R={m['recall']:.3f} F1={m['f1']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix: ResNet50\n",
    "plot_confusion_matrix(\n",
    "    metrics_res[\"confusion_matrix\"],\n",
    "    DISPLAY_NAMES,\n",
    "    title=\"ResNet50 Confusion Matrix\",\n",
    "    save_path=\"results/cm_resnet50.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML results placeholder\n",
    "# Replace these with actual AutoML evaluation output from notebook 04\n",
    "automl_per_class = {\n",
    "    \"12\": {\"recall\": 0.0, \"precision\": 0.0, \"f1\": 0.0},\n",
    "    \"34\": {\"recall\": 0.0, \"precision\": 0.0, \"f1\": 0.0},\n",
    "    \"56\": {\"recall\": 0.0, \"precision\": 0.0, \"f1\": 0.0},\n",
    "}\n",
    "# TODO: Fill in from AutoML evaluation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness gap analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FAIRNESS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fairness_eff = compute_fairness_gap(metrics_eff[\"per_class\"])\n",
    "fairness_res = compute_fairness_gap(metrics_res[\"per_class\"])\n",
    "\n",
    "print(f\"\\nEfficientNetV2-S Fairness Gap: {fairness_eff['gap']:.2%}\")\n",
    "print(f\"  Best:  {fairness_eff['best_class']} ({fairness_eff['best_value']:.2%})\")\n",
    "print(f\"  Worst: {fairness_eff['worst_class']} ({fairness_eff['worst_value']:.2%})\")\n",
    "print(f\"  Significant: {fairness_eff['significant']}\")\n",
    "\n",
    "print(f\"\\nResNet50 Fairness Gap: {fairness_res['gap']:.2%}\")\n",
    "print(f\"  Best:  {fairness_res['best_class']} ({fairness_res['best_value']:.2%})\")\n",
    "print(f\"  Worst: {fairness_res['worst_class']} ({fairness_res['worst_value']:.2%})\")\n",
    "print(f\"  Significant: {fairness_res['significant']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-model fairness comparison\n",
    "model_metrics = {\n",
    "    \"EfficientNetV2-S\": metrics_eff[\"per_class\"],\n",
    "    \"ResNet50\": metrics_res[\"per_class\"],\n",
    "    # \"AutoML\": automl_per_class,  # Uncomment when AutoML results are ready\n",
    "}\n",
    "\n",
    "fairness_results = compare_model_fairness(model_metrics)\n",
    "\n",
    "plot_fairness_comparison(\n",
    "    fairness_results,\n",
    "    save_path=\"results/fairness_comparison.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Model':<20} {'Accuracy':<10} {'Macro F1':<10} {'Fairness Gap':<15} {'Significant?'}\")\n",
    "print(\"-\"*65)\n",
    "for name, m, fg in [\n",
    "    (\"EfficientNetV2-S\", metrics_eff, fairness_eff),\n",
    "    (\"ResNet50\", metrics_res, fairness_res),\n",
    "]:\n",
    "    print(f\"{name:<20} {m['accuracy']:<10.4f} {m['macro_f1']:<10.4f} {fg['gap']:<15.2%} {fg['significant']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
