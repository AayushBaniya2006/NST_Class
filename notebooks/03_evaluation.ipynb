{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 03 â€” Evaluation & Fairness Analysis\nEvaluate EfficientNetV2-S, ResNet50, and AutoML baseline across all 6 Fitzpatrick types.\nCompute per-class metrics and fairness gap."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, subprocess, sys\n\n# Clone repo (skip if already cloned)\nif not os.path.exists(\"/content/NST_Class\"):\n    subprocess.run([\"git\", \"clone\", \"https://github.com/AayushBaniya2006/NST_Class.git\"], cwd=\"/content\")\nos.chdir(\"/content/NST_Class\")\n\n!pip install -q -r requirements.txt\n\nsys.path.insert(0, '/content/NST_Class')\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom torch.utils.data import DataLoader\n\nfrom src.data.dataset import FitzpatrickDataset\nfrom src.data.transforms import get_eval_transforms\nfrom src.models.classifier import SkinToneClassifier\nfrom src.evaluation.metrics import compute_all_metrics\nfrom src.evaluation.fairness import compute_fairness_gap, compare_model_fairness\nfrom src.evaluation.confusion import plot_confusion_matrix, plot_fairness_comparison\n\nprint(\"Setup complete! Make sure you ran notebooks 01 and 02 first.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nIMAGE_DIR = \"data/images\"\nDATA_DIR = \"data/cleaned\"\nCLASS_NAMES = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\nDISPLAY_NAMES = [\"Fitz I\", \"Fitz II\", \"Fitz III\", \"Fitz IV\", \"Fitz V\", \"Fitz VI\"]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load test data\ntest_df = pd.read_csv(f\"{DATA_DIR}/test.csv\")\nprint(f\"Test set: {len(test_df)} images\")\nprint(test_df[\"fitzpatrick\"].value_counts().sort_index())\n\ntransform = get_eval_transforms(224)\ntest_dataset = FitzpatrickDataset(test_df, IMAGE_DIR, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: run inference\n",
    "@torch.no_grad()\n",
    "def get_predictions(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return np.array(all_labels), np.array(all_preds), np.array(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate EfficientNetV2-S\nmodel_eff = SkinToneClassifier(\"efficientnet_v2_s\", num_classes=6, pretrained=False)\nmodel_eff.load_state_dict(torch.load(\"checkpoints/efficientnet_v2_s_final.pt\", map_location=DEVICE, weights_only=True))\nmodel_eff = model_eff.to(DEVICE)\n\ny_true, y_pred_eff, y_proba_eff = get_predictions(model_eff, test_loader, DEVICE)\nmetrics_eff = compute_all_metrics(y_true, y_pred_eff, y_proba_eff, CLASS_NAMES)\n\nprint(\"EfficientNetV2-S Results:\")\nprint(f\"  Accuracy: {metrics_eff['accuracy']:.4f}\")\nprint(f\"  Macro F1: {metrics_eff['macro_f1']:.4f}\")\nprint(f\"  ROC-AUC:  {metrics_eff['roc_auc']:.4f}\")\nfor cls, display in zip(CLASS_NAMES, DISPLAY_NAMES):\n    m = metrics_eff[\"per_class\"][cls]\n    print(f\"  {display}: P={m['precision']:.3f} R={m['recall']:.3f} F1={m['f1']:.3f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix: EfficientNetV2\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "plot_confusion_matrix(\n",
    "    metrics_eff[\"confusion_matrix\"],\n",
    "    DISPLAY_NAMES,\n",
    "    title=\"EfficientNetV2-S Confusion Matrix\",\n",
    "    save_path=\"results/cm_efficientnet.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate ResNet50\nmodel_res = SkinToneClassifier(\"resnet50\", num_classes=6, pretrained=False)\nmodel_res.load_state_dict(torch.load(\"checkpoints/resnet50_final.pt\", map_location=DEVICE, weights_only=True))\nmodel_res = model_res.to(DEVICE)\n\n_, y_pred_res, y_proba_res = get_predictions(model_res, test_loader, DEVICE)\nmetrics_res = compute_all_metrics(y_true, y_pred_res, y_proba_res, CLASS_NAMES)\n\nprint(\"\\nResNet50 Results:\")\nprint(f\"  Accuracy: {metrics_res['accuracy']:.4f}\")\nprint(f\"  Macro F1: {metrics_res['macro_f1']:.4f}\")\nfor cls, display in zip(CLASS_NAMES, DISPLAY_NAMES):\n    m = metrics_res[\"per_class\"][cls]\n    print(f\"  {display}: P={m['precision']:.3f} R={m['recall']:.3f} F1={m['f1']:.3f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix: ResNet50\n",
    "plot_confusion_matrix(\n",
    "    metrics_res[\"confusion_matrix\"],\n",
    "    DISPLAY_NAMES,\n",
    "    title=\"ResNet50 Confusion Matrix\",\n",
    "    save_path=\"results/cm_resnet50.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# AutoML results placeholder\n# Replace these with actual AutoML evaluation output from notebook 04\nautoml_per_class = {\n    \"1\": {\"recall\": 0.0, \"precision\": 0.0, \"f1\": 0.0},\n    \"2\": {\"recall\": 0.0, \"precision\": 0.0, \"f1\": 0.0},\n    \"3\": {\"recall\": 0.0, \"precision\": 0.0, \"f1\": 0.0},\n    \"4\": {\"recall\": 0.0, \"precision\": 0.0, \"f1\": 0.0},\n    \"5\": {\"recall\": 0.0, \"precision\": 0.0, \"f1\": 0.0},\n    \"6\": {\"recall\": 0.0, \"precision\": 0.0, \"f1\": 0.0},\n}\n# TODO: Fill in from AutoML evaluation output"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness gap analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FAIRNESS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fairness_eff = compute_fairness_gap(metrics_eff[\"per_class\"])\n",
    "fairness_res = compute_fairness_gap(metrics_res[\"per_class\"])\n",
    "\n",
    "print(f\"\\nEfficientNetV2-S Fairness Gap: {fairness_eff['gap']:.2%}\")\n",
    "print(f\"  Best:  {fairness_eff['best_class']} ({fairness_eff['best_value']:.2%})\")\n",
    "print(f\"  Worst: {fairness_eff['worst_class']} ({fairness_eff['worst_value']:.2%})\")\n",
    "print(f\"  Significant: {fairness_eff['significant']}\")\n",
    "\n",
    "print(f\"\\nResNet50 Fairness Gap: {fairness_res['gap']:.2%}\")\n",
    "print(f\"  Best:  {fairness_res['best_class']} ({fairness_res['best_value']:.2%})\")\n",
    "print(f\"  Worst: {fairness_res['worst_class']} ({fairness_res['worst_value']:.2%})\")\n",
    "print(f\"  Significant: {fairness_res['significant']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-model fairness comparison\n",
    "model_metrics = {\n",
    "    \"EfficientNetV2-S\": metrics_eff[\"per_class\"],\n",
    "    \"ResNet50\": metrics_res[\"per_class\"],\n",
    "    # \"AutoML\": automl_per_class,  # Uncomment when AutoML results are ready\n",
    "}\n",
    "\n",
    "fairness_results = compare_model_fairness(model_metrics)\n",
    "\n",
    "plot_fairness_comparison(\n",
    "    fairness_results,\n",
    "    save_path=\"results/fairness_comparison.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Model':<20} {'Accuracy':<10} {'Macro F1':<10} {'Fairness Gap':<15} {'Significant?'}\")\n",
    "print(\"-\"*65)\n",
    "for name, m, fg in [\n",
    "    (\"EfficientNetV2-S\", metrics_eff, fairness_eff),\n",
    "    (\"ResNet50\", metrics_res, fairness_res),\n",
    "]:\n",
    "    print(f\"{name:<20} {m['accuracy']:<10.4f} {m['macro_f1']:<10.4f} {fg['gap']:<15.2%} {fg['significant']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}